{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae599fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e6e84ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_save_path_X_train = 'D:\\\\Code\\\\datascience\\\\MA_NFT\\\\data\\\\pickle\\\\dummy_x.pkl'\n",
    "pickle_save_path_y_train = 'D:\\\\Code\\\\datascience\\\\MA_NFT\\\\data\\\\pickle\\\\dummy_y.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "541745d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_x = pd.DataFrame(data={\n",
    "    'id': ['1', '2', '3' , '4'],\n",
    "    'img_path': ['C:\\\\nft_data\\\\preview\\\\__hqB34BOi708uD1pUK1_noext.png', None, None, None],\n",
    "    'preview_path': [None, 'C:\\\\nft_data\\\\preview\\\\Z9_LE34BOa5kXuiNx1Au_noext.png', \n",
    "                     'C:\\\\nft_data\\\\preview\\\\z13JZn4B3CmUIj-Jo9QZ_noext.png', None]\n",
    "})\n",
    "# $:\n",
    "#df_y = pd.Series([2, 20, 423456, 423456]).astype('category')\n",
    "df_y = pd.Series([0, 1, 2, 2]).astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfddc85a",
   "metadata": {},
   "source": [
    "df_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a909293",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pickle_save_path_X_train,'wb') as path_name:\n",
    "    pickle.dump(df_x, path_name) \n",
    "with open(pickle_save_path_y_train,'wb') as path_name:\n",
    "    pickle.dump(df_y, path_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5253e1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0881d3",
   "metadata": {},
   "source": [
    "import torchvision.transforms as T\n",
    "trf = T.Compose([T.RandomResizedCrop(size=250, scale=(0.8, 1.0)),\n",
    "             T.CenterCrop(224),\n",
    "             T.RandomRotation(degrees=15),\n",
    "             T.ColorJitter(),\n",
    "             T.RandomHorizontalFlip(),\n",
    "             T.ToTensor(), \n",
    "             T.Normalize(mean = [0.485, 0.456, 0.406], \n",
    "                         std = [0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40a0c38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image transformations\n",
    "img_transforms = {\n",
    "    # Train uses data augmentation\n",
    "    'train':\n",
    "    T.Compose([\n",
    "        T.RandomResizedCrop(size=250, scale=(0.8, 1.0)),\n",
    "        T.RandomRotation(degrees=15),\n",
    "        T.ColorJitter(),\n",
    "        T.RandomHorizontalFlip(),\n",
    "        T.CenterCrop(size=224),  # Image net standards\n",
    "        T.ToTensor(),\n",
    "        T.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])  # Imagenet standards\n",
    "    ]),\n",
    "    # Validation does not use augmentation\n",
    "    'valid':\n",
    "    T.Compose([\n",
    "        T.Resize(size=250),\n",
    "        T.CenterCrop(size=224),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    \n",
    "        # Test does not use augmentation\n",
    "    'test':\n",
    "    T.Compose([\n",
    "        T.Resize(size=250),\n",
    "        T.CenterCrop(size=224),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ccfc8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickledataset import PickleSeriesDataset\n",
    "from collate import collate_none_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab45d20",
   "metadata": {},
   "source": [
    "with open(pickle_save_path,'wb') as path_name:\n",
    "    pickle.dump(img_df, path_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b498be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = PickleSeriesDataset(pickle_save_path_X_train, pickle_save_path_y_train, img_transforms['train'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ea7d75",
   "metadata": {},
   "source": [
    "for ii, (data, target) in enumerate(ds_test):\n",
    "    print(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "851fc3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(\n",
    "        PickleSeriesDataset(pickle_save_path_X_train, pickle_save_path_y_train, trf), \n",
    "        batch_size=2,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        collate_fn=collate_none_values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15215fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(tensor([[[1.4783, 1.4783, 1.4783,  ..., 1.4783, 1.4783, 1.4783],\n",
       "            [1.4783, 1.4783, 1.4783,  ..., 1.4783, 1.4783, 1.4783],\n",
       "            [1.4783, 1.4783, 1.4783,  ..., 1.4783, 1.4783, 1.4783],\n",
       "            ...,\n",
       "            [1.4783, 1.4783, 1.4783,  ..., 1.4269, 1.4954, 1.4783],\n",
       "            [1.4783, 1.4783, 1.4783,  ..., 1.5125, 1.4783, 1.5125],\n",
       "            [1.4783, 1.4783, 1.4783,  ..., 1.4954, 1.4783, 1.5125]],\n",
       "   \n",
       "           [[1.5182, 1.5182, 1.5182,  ..., 1.5182, 1.5182, 1.5182],\n",
       "            [1.5182, 1.5182, 1.5182,  ..., 1.5182, 1.5182, 1.5182],\n",
       "            [1.5182, 1.5182, 1.5182,  ..., 1.5182, 1.5182, 1.5182],\n",
       "            ...,\n",
       "            [1.5182, 1.5182, 1.5182,  ..., 1.4657, 1.5357, 1.4832],\n",
       "            [1.5182, 1.5182, 1.5182,  ..., 1.5532, 1.5182, 1.5182],\n",
       "            [1.5182, 1.5182, 1.5182,  ..., 1.5357, 1.5182, 1.5182]],\n",
       "   \n",
       "           [[0.7925, 0.7925, 0.7925,  ..., 0.7925, 0.7925, 0.7925],\n",
       "            [0.7925, 0.7925, 0.7925,  ..., 0.7925, 0.7925, 0.7925],\n",
       "            [0.7925, 0.7925, 0.7925,  ..., 0.7925, 0.7925, 0.7925],\n",
       "            ...,\n",
       "            [0.7925, 0.7925, 0.7925,  ..., 0.7228, 0.8448, 0.7402],\n",
       "            [0.7925, 0.7925, 0.7925,  ..., 0.8099, 0.8274, 0.7751],\n",
       "            [0.7925, 0.7925, 0.7925,  ..., 0.8099, 0.8274, 0.7751]]]),\n",
       "   tensor(10))],\n",
       " [(tensor([[[-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
       "            [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
       "            [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
       "            ...,\n",
       "            [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
       "            [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
       "            [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103]],\n",
       "   \n",
       "           [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
       "            [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
       "            [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
       "            ...,\n",
       "            [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
       "            [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
       "            [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
       "   \n",
       "           [[ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
       "            [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
       "            [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
       "            ...,\n",
       "            [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
       "            [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
       "            [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062]]]),\n",
       "   tensor(2))],\n",
       " [(tensor([[[2.1804, 1.1872, 0.6563,  ..., 2.2489, 2.2489, 2.2489],\n",
       "            [2.2147, 1.5468, 1.2728,  ..., 2.2489, 2.2489, 2.2489],\n",
       "            [2.1975, 1.2899, 0.8618,  ..., 2.2489, 2.2489, 2.2489],\n",
       "            ...,\n",
       "            [0.0912, 0.0912, 0.0912,  ..., 0.0912, 0.0912, 0.0912],\n",
       "            [0.0912, 0.0912, 0.0912,  ..., 0.0912, 0.0912, 0.0912],\n",
       "            [0.0912, 0.0912, 0.0912,  ..., 0.0912, 0.0912, 0.0912]],\n",
       "   \n",
       "           [[2.3585, 1.3431, 0.8004,  ..., 2.4286, 2.4286, 2.4286],\n",
       "            [2.3936, 1.7108, 1.4307,  ..., 2.4286, 2.4286, 2.4286],\n",
       "            [2.3761, 1.4482, 1.0105,  ..., 2.4286, 2.4286, 2.4286],\n",
       "            ...,\n",
       "            [1.0805, 1.0805, 1.0805,  ..., 1.0805, 1.0805, 1.0805],\n",
       "            [1.0805, 1.0805, 1.0805,  ..., 1.0805, 1.0805, 1.0805],\n",
       "            [1.0805, 1.0805, 1.0805,  ..., 1.0805, 1.0805, 1.0805]],\n",
       "   \n",
       "           [[2.5703, 1.5594, 1.0191,  ..., 2.6400, 2.6400, 2.6400],\n",
       "            [2.6051, 1.9254, 1.6465,  ..., 2.6400, 2.6400, 2.6400],\n",
       "            [2.5877, 1.6640, 1.2282,  ..., 2.6400, 2.6400, 2.6400],\n",
       "            ...,\n",
       "            [0.8797, 0.8797, 0.8797,  ..., 0.8797, 0.8797, 0.8797],\n",
       "            [0.8797, 0.8797, 0.8797,  ..., 0.8797, 0.8797, 0.8797],\n",
       "            [0.8797, 0.8797, 0.8797,  ..., 0.8797, 0.8797, 0.8797]]]),\n",
       "   tensor(300))]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d460941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELMENT 0\n",
      "tensor(10)\n",
      "ELMENT 1\n",
      "tensor(2)\n",
      "ELMENT 2\n",
      "tensor(300)\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for l in test_loader:\n",
    "    for (img, t) in l:\n",
    "        print(f'ELMENT {i}')\n",
    "        print(t)\n",
    "        i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c72416aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_29296/1150282151.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mii\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "for ii, (data, target) in enumerate(test_loader):\n",
    "    print(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9c6f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29459954",
   "metadata": {},
   "outputs": [],
   "source": [
    "[b for b in [1,2,3,None,5] if b is not None ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5905cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = PickleSeriesDataset(pickle_save_path_X_train, pickle_save_path_y_train, trf)\n",
    "list(DataLoader(ds, num_workers=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788a1535",
   "metadata": {},
   "source": [
    "# Test ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0347a050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cluster_name': 'es-docker-cluster',\n",
       " 'status': 'yellow',\n",
       " 'timed_out': False,\n",
       " 'number_of_nodes': 1,\n",
       " 'number_of_data_nodes': 1,\n",
       " 'active_primary_shards': 15,\n",
       " 'active_shards': 15,\n",
       " 'relocating_shards': 0,\n",
       " 'initializing_shards': 0,\n",
       " 'unassigned_shards': 2,\n",
       " 'delayed_unassigned_shards': 0,\n",
       " 'number_of_pending_tasks': 0,\n",
       " 'number_of_in_flight_fetch': 0,\n",
       " 'task_max_waiting_in_queue_millis': 0,\n",
       " 'active_shards_percent_as_number': 88.23529411764706}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch_dsl import Search\n",
    "import json\n",
    "import requests\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# create a client instance of the library\n",
    "elastic_client = Elasticsearch(timeout=60, max_retries=10, retry_on_timeout=True)\n",
    "elastic_client.cluster.health(wait_for_status='yellow', request_timeout=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59986d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from glob import glob\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "#from torchsummary import summary\n",
    "from torchvision import transforms, datasets, models\n",
    "import torch\n",
    "from torch import optim, cuda\n",
    "from torch.utils.data import DataLoader, sampler\n",
    "import torch.nn as nn\n",
    "import tqdm\n",
    "from timeit import default_timer as timer\n",
    "from torch import Tensor, nn\n",
    "from torch.nn.functional import interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a1b184e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file_name = 'C:\\\\NFT_data\\\\networks\\\\resnet50-transfer_test.pt'\n",
    "checkpoint_path = 'C:\\\\NFT_data\\\\networks\\\\resnet50-transfer_test.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb0ad18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on gpu: True\n",
      "1 gpus detected.\n",
      "True False\n"
     ]
    }
   ],
   "source": [
    "# Change to fit hardware\n",
    "batch_size = 1024\n",
    "\n",
    "# Whether to train on a gpu\n",
    "train_on_gpu = cuda.is_available()\n",
    "print(f'Train on gpu: {train_on_gpu}')\n",
    "\n",
    "# Number of gpus\n",
    "if train_on_gpu:\n",
    "    gpu_count = cuda.device_count()\n",
    "    print(f'{gpu_count} gpus detected.')\n",
    "    if gpu_count > 1:\n",
    "        multi_gpu = True\n",
    "    else:\n",
    "        multi_gpu = False\n",
    "print(train_on_gpu,multi_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59a18ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [2, 20, 423456]\n",
    "# restart for ResNet\n",
    "# Step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b20f2483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.0-2.0', '2.0-20.0', '20.0-423456.0']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_labels = []\n",
    "for i in range(0, len(bins)):\n",
    "    start = 0\n",
    "    if i > 0:\n",
    "        start = bins[i-1]\n",
    "    end = bins[i]\n",
    "    s = '{:.1f}'.format(start)\n",
    "    e = '{:.1f}'.format(end)\n",
    "    bin_labels.append(f'{s}-{e}')\n",
    "bin_labels\n",
    "# restart for ResNet\n",
    "# Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6f90a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0.0-2.0': 0, '2.0-20.0': 1, '20.0-423456.0': 2}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_class = {\n",
    "    idx: class_\n",
    "    for idx, class_ in enumerate(bin_labels)\n",
    "}\n",
    "class_to_idx = {bin_labels[i]: i for i in range(len(bin_labels))}\n",
    "\n",
    "class_to_idx\n",
    "# Restart for ResNet\n",
    "# Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b280c0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 different classes.\n"
     ]
    }
   ],
   "source": [
    "n_classes = len(bin_labels)\n",
    "print(f'There are {n_classes} different classes.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06b62d8",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa87fac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained = True)\n",
    "#Freeze our model's weights because we use pretrained one\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c9e1718",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = model.fc.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d742e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Sequential(\n",
    "                      nn.Linear(n_inputs, 250), \n",
    "                      nn.ReLU(), \n",
    "                      nn.Dropout(0.4),\n",
    "                      nn.Linear(250, n_classes),                   \n",
    "                      nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0058e864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2048, out_features=250, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Dropout(p=0.4, inplace=False)\n",
       "  (3): Linear(in_features=250, out_features=3, bias=True)\n",
       "  (4): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f4ff6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24,021,035 total parameters.\n",
      "513,003 training parameters.\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'{total_params:,} total parameters.')\n",
    "total_trainable_params = sum(\n",
    "    p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'{total_trainable_params:,} training parameters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53cc4ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_on_gpu:\n",
    "    model = model.to('cuda')\n",
    "\n",
    "if multi_gpu:\n",
    "    model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5d65d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=2048, out_features=250, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Dropout(p=0.4, inplace=False)\n",
      "  (3): Linear(in_features=250, out_features=3, bias=True)\n",
      "  (4): LogSoftmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "if multi_gpu:\n",
    "    print(model.module.fc)\n",
    "else:\n",
    "    print(model.fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bb03661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '0.0-2.0'), (1, '2.0-20.0'), (2, '20.0-423456.0')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.class_to_idx = class_to_idx\n",
    "model.idx_to_class = idx_to_class\n",
    "\n",
    "list(model.idx_to_class.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3bf63629",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3d0fbfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([250, 2048])\n",
      "torch.Size([250])\n",
      "torch.Size([3, 250])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "for p in optimizer.param_groups[0]['params']:\n",
    "    if p.requires_grad:\n",
    "        print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86817989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "trf = T.Compose([T.Resize(250),\n",
    "             T.CenterCrop(224),\n",
    "             T.ToTensor(), \n",
    "             T.Normalize(mean = [0.485, 0.456, 0.406], \n",
    "                         std = [0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1963c98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickledataset import PickleSeriesDataset\n",
    "from collate import collate_none_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc87e860",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(\n",
    "        PickleSeriesDataset(pickle_save_path_X_train, pickle_save_path_y_train, trf), \n",
    "        batch_size=2,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        #collate_fn=collate_none_values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "208434e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,\n",
    "          criterion,\n",
    "          optimizer,\n",
    "          train_loader,\n",
    "          valid_loader,\n",
    "          save_file_name,\n",
    "          max_epochs_stop=3,\n",
    "          n_epochs=20,\n",
    "          print_every=1):\n",
    "    \"\"\"Train a PyTorch Model\n",
    "\n",
    "    Params\n",
    "    --------\n",
    "        model (PyTorch model): cnn to train\n",
    "        criterion (PyTorch loss): objective to minimize\n",
    "        optimizer (PyTorch optimizier): optimizer to compute gradients of model parameters\n",
    "        train_loader (PyTorch dataloader): training dataloader to iterate through\n",
    "        valid_loader (PyTorch dataloader): validation dataloader used for early stopping\n",
    "        save_file_name (str ending in '.pt'): file path to save the model state dict\n",
    "        max_epochs_stop (int): maximum number of epochs with no improvement in validation loss for early stopping\n",
    "        n_epochs (int): maximum number of training epochs\n",
    "        print_every (int): frequency of epochs to print training stats\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "        model (PyTorch model): trained cnn with best weights\n",
    "        history (DataFrame): history of train and validation loss and accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    # Early stopping intialization\n",
    "    epochs_no_improve = 0\n",
    "    valid_loss_min = np.Inf\n",
    "\n",
    "    valid_max_acc = 0\n",
    "    history = []\n",
    "\n",
    "    # Number of epochs already trained (if using loaded in model weights)\n",
    "    try:\n",
    "        print(f'Model has been trained for: {model.epochs} epochs.\\n')\n",
    "    except:\n",
    "        model.epochs = 0\n",
    "        print(f'Starting Training from Scratch.\\n')\n",
    "\n",
    "    overall_start = timer()\n",
    "\n",
    "    # Main loop\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        # keep track of training and validation loss each epoch\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "\n",
    "        train_acc = 0\n",
    "        valid_acc = 0\n",
    "\n",
    "        # Set to training\n",
    "        model.train()\n",
    "        start = timer()\n",
    "\n",
    "        # Training loop\n",
    "        for ii, (data, target) in enumerate(train_loader):\n",
    "        #ii = 0\n",
    "        #for worker_data in train_loader:\n",
    "        #    for (data, target) in worker_data:\n",
    "                print(data)\n",
    "                print(target)\n",
    "\n",
    "                # Tensors to gpu\n",
    "                if train_on_gpu:\n",
    "                    data, target = data.cuda(), target.cuda()\n",
    "\n",
    "                # Clear gradients\n",
    "                optimizer.zero_grad()\n",
    "                # Predicted outputs are log probabilities\n",
    "                output = model(data)\n",
    "\n",
    "                # Loss and backpropagation of gradients\n",
    "                loss = criterion(output, target)\n",
    "                loss.backward()\n",
    "\n",
    "                # Update the parameters\n",
    "                optimizer.step()\n",
    "\n",
    "                # Track train loss by multiplying average loss by number of examples in batch\n",
    "                train_loss += loss.item() * data.size(0)\n",
    "\n",
    "                # Calculate accuracy by finding max log probability\n",
    "                _, pred = torch.max(output, dim=1)\n",
    "                correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "                # Need to convert correct tensor from int to float to average\n",
    "                accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n",
    "                # Multiply average accuracy times the number of examples in batch\n",
    "                train_acc += accuracy.item() * data.size(0)\n",
    "\n",
    "                # Track training progress\n",
    "                print(\n",
    "                    f'Epoch: {epoch}\\t{100 * (ii + 1) / len(train_loader):.2f}% complete. {timer() - start:.2f} seconds elapsed in epoch.',\n",
    "                    end='\\r')\n",
    "                \n",
    "                # increase\n",
    "                ii += 1\n",
    "\n",
    "        # After training loops ends, start validation\n",
    "        else:\n",
    "            model.epochs += 1\n",
    "\n",
    "            # Don't need to keep track of gradients\n",
    "            with torch.no_grad():\n",
    "                # Set to evaluation mode\n",
    "                model.eval()\n",
    "\n",
    "                # Validation loop\n",
    "                for data, target in valid_loader:\n",
    "                    # Tensors to gpu\n",
    "                    if train_on_gpu:\n",
    "                        data, target = data.cuda(), target.cuda()\n",
    "\n",
    "                    # Forward pass\n",
    "                    output = model(data)\n",
    "\n",
    "                    # Validation loss\n",
    "                    loss = criterion(output, target)\n",
    "                    # Multiply average loss times the number of examples in batch\n",
    "                    valid_loss += loss.item() * data.size(0)\n",
    "\n",
    "                    # Calculate validation accuracy\n",
    "                    _, pred = torch.max(output, dim=1)\n",
    "                    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "                    accuracy = torch.mean(\n",
    "                        correct_tensor.type(torch.FloatTensor))\n",
    "                    # Multiply average accuracy times the number of examples\n",
    "                    valid_acc += accuracy.item() * data.size(0)\n",
    "\n",
    "                # Calculate average losses\n",
    "                train_loss = train_loss / len(train_loader.dataset)\n",
    "                valid_loss = valid_loss / len(valid_loader.dataset)\n",
    "\n",
    "                # Calculate average accuracy\n",
    "                train_acc = train_acc / len(train_loader.dataset)\n",
    "                valid_acc = valid_acc / len(valid_loader.dataset)\n",
    "\n",
    "                history.append([train_loss, valid_loss, train_acc, valid_acc])\n",
    "\n",
    "                # Print training and validation results\n",
    "                if (epoch + 1) % print_every == 0:\n",
    "                    print(\n",
    "                        f'\\nEpoch: {epoch} \\tTraining Loss: {train_loss:.4f} \\tValidation Loss: {valid_loss:.4f}'\n",
    "                    )\n",
    "                    print(\n",
    "                        f'\\t\\tTraining Accuracy: {100 * train_acc:.2f}%\\t Validation Accuracy: {100 * valid_acc:.2f}%'\n",
    "                    )\n",
    "\n",
    "                # Save the model if validation loss decreases\n",
    "                if valid_loss < valid_loss_min:\n",
    "                    # Save model\n",
    "                    torch.save(model.state_dict(), save_file_name)\n",
    "                    # Track improvement\n",
    "                    epochs_no_improve = 0\n",
    "                    valid_loss_min = valid_loss\n",
    "                    valid_best_acc = valid_acc\n",
    "                    best_epoch = epoch\n",
    "\n",
    "                # Otherwise increment count of epochs with no improvement\n",
    "                else:\n",
    "                    epochs_no_improve += 1\n",
    "                    # Trigger early stopping\n",
    "                    if epochs_no_improve >= max_epochs_stop:\n",
    "                        print(\n",
    "                            f'\\nEarly Stopping! Total epochs: {epoch}. Best epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%'\n",
    "                        )\n",
    "                        total_time = timer() - overall_start\n",
    "                        print(\n",
    "                            f'{total_time:.2f} total seconds elapsed. {total_time / (epoch+1):.2f} seconds per epoch.'\n",
    "                        )\n",
    "\n",
    "                        # Load the best state dict\n",
    "                        model.load_state_dict(torch.load(save_file_name))\n",
    "                        # Attach the optimizer\n",
    "                        model.optimizer = optimizer\n",
    "\n",
    "                        # Format history\n",
    "                        history = pd.DataFrame(\n",
    "                            history,\n",
    "                            columns=[\n",
    "                                'train_loss', 'valid_loss', 'train_acc',\n",
    "                                'valid_acc'\n",
    "                            ])\n",
    "                        return model, history\n",
    "\n",
    "    # Attach the optimizer\n",
    "    model.optimizer = optimizer\n",
    "    # Record overall time and print out stats\n",
    "    total_time = timer() - overall_start\n",
    "    print(\n",
    "        f'\\nBest epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%'\n",
    "    )\n",
    "    print(\n",
    "        f'{total_time:.2f} total seconds elapsed. {total_time / (epoch):.2f} seconds per epoch.'\n",
    "    )\n",
    "    # Format history\n",
    "    history = pd.DataFrame(\n",
    "        history,\n",
    "        columns=['train_loss', 'valid_loss', 'train_acc', 'valid_acc'])\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4f38195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training from Scratch.\n",
      "\n",
      "tensor([[[[1.4783, 1.4783, 1.4783,  ..., 1.4783, 1.4783, 1.4783],\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.4783, 1.4783, 1.4783],\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.4783, 1.4783, 1.4783],\n",
      "          ...,\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.4269, 1.4954, 1.4783],\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.5125, 1.4783, 1.5125],\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.4954, 1.4783, 1.5125]],\n",
      "\n",
      "         [[1.5182, 1.5182, 1.5182,  ..., 1.5182, 1.5182, 1.5182],\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.5182, 1.5182, 1.5182],\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.5182, 1.5182, 1.5182],\n",
      "          ...,\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.4657, 1.5357, 1.4832],\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.5532, 1.5182, 1.5182],\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.5357, 1.5182, 1.5182]],\n",
      "\n",
      "         [[0.7925, 0.7925, 0.7925,  ..., 0.7925, 0.7925, 0.7925],\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.7925, 0.7925, 0.7925],\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.7925, 0.7925, 0.7925],\n",
      "          ...,\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.7228, 0.8448, 0.7402],\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.8099, 0.8274, 0.7751],\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.8099, 0.8274, 0.7751]]]])\n",
      "tensor([0])\n",
      "tensor([[[[-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          ...,\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          ...,\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062]]]])\n",
      "tensor([1])\n",
      "tensor([[[[2.1804, 1.1872, 0.6563,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2147, 1.5468, 1.2728,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.1975, 1.2899, 0.8618,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          ...,\n",
      "          [0.0912, 0.0912, 0.0912,  ..., 0.0912, 0.0912, 0.0912],\n",
      "          [0.0912, 0.0912, 0.0912,  ..., 0.0912, 0.0912, 0.0912],\n",
      "          [0.0912, 0.0912, 0.0912,  ..., 0.0912, 0.0912, 0.0912]],\n",
      "\n",
      "         [[2.3585, 1.3431, 0.8004,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.3936, 1.7108, 1.4307,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.3761, 1.4482, 1.0105,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          ...,\n",
      "          [1.0805, 1.0805, 1.0805,  ..., 1.0805, 1.0805, 1.0805],\n",
      "          [1.0805, 1.0805, 1.0805,  ..., 1.0805, 1.0805, 1.0805],\n",
      "          [1.0805, 1.0805, 1.0805,  ..., 1.0805, 1.0805, 1.0805]],\n",
      "\n",
      "         [[2.5703, 1.5594, 1.0191,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6051, 1.9254, 1.6465,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.5877, 1.6640, 1.2282,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          ...,\n",
      "          [0.8797, 0.8797, 0.8797,  ..., 0.8797, 0.8797, 0.8797],\n",
      "          [0.8797, 0.8797, 0.8797,  ..., 0.8797, 0.8797, 0.8797],\n",
      "          [0.8797, 0.8797, 0.8797,  ..., 0.8797, 0.8797, 0.8797]]]])\n",
      "tensor([2])\n",
      "Epoch: 0\t150.00% complete. 2.91 seconds elapsed in epoch.\n",
      "Epoch: 0 \tTraining Loss: 1.4756 \tValidation Loss: 1.1504\n",
      "\t\tTraining Accuracy: 0.00%\t Validation Accuracy: 25.00%\n",
      "tensor([[[[1.4783, 1.4783, 1.4783,  ..., 1.4783, 1.4783, 1.4783],\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.4783, 1.4783, 1.4783],\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.4783, 1.4783, 1.4783],\n",
      "          ...,\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.4269, 1.4954, 1.4783],\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.5125, 1.4783, 1.5125],\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.4954, 1.4783, 1.5125]],\n",
      "\n",
      "         [[1.5182, 1.5182, 1.5182,  ..., 1.5182, 1.5182, 1.5182],\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.5182, 1.5182, 1.5182],\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.5182, 1.5182, 1.5182],\n",
      "          ...,\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.4657, 1.5357, 1.4832],\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.5532, 1.5182, 1.5182],\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.5357, 1.5182, 1.5182]],\n",
      "\n",
      "         [[0.7925, 0.7925, 0.7925,  ..., 0.7925, 0.7925, 0.7925],\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.7925, 0.7925, 0.7925],\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.7925, 0.7925, 0.7925],\n",
      "          ...,\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.7228, 0.8448, 0.7402],\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.8099, 0.8274, 0.7751],\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.8099, 0.8274, 0.7751]]]])\n",
      "tensor([0])\n",
      "tensor([[[[-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          ...,\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          ...,\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062]]]])\n",
      "tensor([1])\n",
      "tensor([[[[2.1804, 1.1872, 0.6563,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2147, 1.5468, 1.2728,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.1975, 1.2899, 0.8618,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          ...,\n",
      "          [0.0912, 0.0912, 0.0912,  ..., 0.0912, 0.0912, 0.0912],\n",
      "          [0.0912, 0.0912, 0.0912,  ..., 0.0912, 0.0912, 0.0912],\n",
      "          [0.0912, 0.0912, 0.0912,  ..., 0.0912, 0.0912, 0.0912]],\n",
      "\n",
      "         [[2.3585, 1.3431, 0.8004,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.3936, 1.7108, 1.4307,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.3761, 1.4482, 1.0105,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          ...,\n",
      "          [1.0805, 1.0805, 1.0805,  ..., 1.0805, 1.0805, 1.0805],\n",
      "          [1.0805, 1.0805, 1.0805,  ..., 1.0805, 1.0805, 1.0805],\n",
      "          [1.0805, 1.0805, 1.0805,  ..., 1.0805, 1.0805, 1.0805]],\n",
      "\n",
      "         [[2.5703, 1.5594, 1.0191,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6051, 1.9254, 1.6465,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.5877, 1.6640, 1.2282,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          ...,\n",
      "          [0.8797, 0.8797, 0.8797,  ..., 0.8797, 0.8797, 0.8797],\n",
      "          [0.8797, 0.8797, 0.8797,  ..., 0.8797, 0.8797, 0.8797],\n",
      "          [0.8797, 0.8797, 0.8797,  ..., 0.8797, 0.8797, 0.8797]]]])\n",
      "tensor([2])\n",
      "Epoch: 1\t150.00% complete. 1.05 seconds elapsed in epoch.\n",
      "Epoch: 1 \tTraining Loss: 1.3455 \tValidation Loss: 0.9175\n",
      "\t\tTraining Accuracy: 25.00%\t Validation Accuracy: 25.00%\n",
      "tensor([[[[1.4783, 1.4783, 1.4783,  ..., 1.4783, 1.4783, 1.4783],\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.4783, 1.4783, 1.4783],\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.4783, 1.4783, 1.4783],\n",
      "          ...,\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.4269, 1.4954, 1.4783],\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.5125, 1.4783, 1.5125],\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.4954, 1.4783, 1.5125]],\n",
      "\n",
      "         [[1.5182, 1.5182, 1.5182,  ..., 1.5182, 1.5182, 1.5182],\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.5182, 1.5182, 1.5182],\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.5182, 1.5182, 1.5182],\n",
      "          ...,\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.4657, 1.5357, 1.4832],\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.5532, 1.5182, 1.5182],\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.5357, 1.5182, 1.5182]],\n",
      "\n",
      "         [[0.7925, 0.7925, 0.7925,  ..., 0.7925, 0.7925, 0.7925],\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.7925, 0.7925, 0.7925],\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.7925, 0.7925, 0.7925],\n",
      "          ...,\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.7228, 0.8448, 0.7402],\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.8099, 0.8274, 0.7751],\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.8099, 0.8274, 0.7751]]]])\n",
      "tensor([0])\n",
      "tensor([[[[-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          ...,\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          ...,\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062]]]])\n",
      "tensor([1])\n",
      "tensor([[[[2.1804, 1.1872, 0.6563,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2147, 1.5468, 1.2728,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.1975, 1.2899, 0.8618,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          ...,\n",
      "          [0.0912, 0.0912, 0.0912,  ..., 0.0912, 0.0912, 0.0912],\n",
      "          [0.0912, 0.0912, 0.0912,  ..., 0.0912, 0.0912, 0.0912],\n",
      "          [0.0912, 0.0912, 0.0912,  ..., 0.0912, 0.0912, 0.0912]],\n",
      "\n",
      "         [[2.3585, 1.3431, 0.8004,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.3936, 1.7108, 1.4307,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.3761, 1.4482, 1.0105,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          ...,\n",
      "          [1.0805, 1.0805, 1.0805,  ..., 1.0805, 1.0805, 1.0805],\n",
      "          [1.0805, 1.0805, 1.0805,  ..., 1.0805, 1.0805, 1.0805],\n",
      "          [1.0805, 1.0805, 1.0805,  ..., 1.0805, 1.0805, 1.0805]],\n",
      "\n",
      "         [[2.5703, 1.5594, 1.0191,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6051, 1.9254, 1.6465,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.5877, 1.6640, 1.2282,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          ...,\n",
      "          [0.8797, 0.8797, 0.8797,  ..., 0.8797, 0.8797, 0.8797],\n",
      "          [0.8797, 0.8797, 0.8797,  ..., 0.8797, 0.8797, 0.8797],\n",
      "          [0.8797, 0.8797, 0.8797,  ..., 0.8797, 0.8797, 0.8797]]]])\n",
      "tensor([2])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2\t150.00% complete. 1.15 seconds elapsed in epoch.\n",
      "Epoch: 2 \tTraining Loss: 1.1558 \tValidation Loss: 0.8488\n",
      "\t\tTraining Accuracy: 0.00%\t Validation Accuracy: 25.00%\n",
      "tensor([[[[1.4783, 1.4783, 1.4783,  ..., 1.4783, 1.4783, 1.4783],\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.4783, 1.4783, 1.4783],\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.4783, 1.4783, 1.4783],\n",
      "          ...,\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.4269, 1.4954, 1.4783],\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.5125, 1.4783, 1.5125],\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.4954, 1.4783, 1.5125]],\n",
      "\n",
      "         [[1.5182, 1.5182, 1.5182,  ..., 1.5182, 1.5182, 1.5182],\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.5182, 1.5182, 1.5182],\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.5182, 1.5182, 1.5182],\n",
      "          ...,\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.4657, 1.5357, 1.4832],\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.5532, 1.5182, 1.5182],\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.5357, 1.5182, 1.5182]],\n",
      "\n",
      "         [[0.7925, 0.7925, 0.7925,  ..., 0.7925, 0.7925, 0.7925],\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.7925, 0.7925, 0.7925],\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.7925, 0.7925, 0.7925],\n",
      "          ...,\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.7228, 0.8448, 0.7402],\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.8099, 0.8274, 0.7751],\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.8099, 0.8274, 0.7751]]]])\n",
      "tensor([0])\n",
      "tensor([[[[-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          ...,\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          ...,\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062]]]])\n",
      "tensor([1])\n",
      "tensor([[[[2.1804, 1.1872, 0.6563,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2147, 1.5468, 1.2728,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.1975, 1.2899, 0.8618,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          ...,\n",
      "          [0.0912, 0.0912, 0.0912,  ..., 0.0912, 0.0912, 0.0912],\n",
      "          [0.0912, 0.0912, 0.0912,  ..., 0.0912, 0.0912, 0.0912],\n",
      "          [0.0912, 0.0912, 0.0912,  ..., 0.0912, 0.0912, 0.0912]],\n",
      "\n",
      "         [[2.3585, 1.3431, 0.8004,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.3936, 1.7108, 1.4307,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.3761, 1.4482, 1.0105,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          ...,\n",
      "          [1.0805, 1.0805, 1.0805,  ..., 1.0805, 1.0805, 1.0805],\n",
      "          [1.0805, 1.0805, 1.0805,  ..., 1.0805, 1.0805, 1.0805],\n",
      "          [1.0805, 1.0805, 1.0805,  ..., 1.0805, 1.0805, 1.0805]],\n",
      "\n",
      "         [[2.5703, 1.5594, 1.0191,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6051, 1.9254, 1.6465,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.5877, 1.6640, 1.2282,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          ...,\n",
      "          [0.8797, 0.8797, 0.8797,  ..., 0.8797, 0.8797, 0.8797],\n",
      "          [0.8797, 0.8797, 0.8797,  ..., 0.8797, 0.8797, 0.8797],\n",
      "          [0.8797, 0.8797, 0.8797,  ..., 0.8797, 0.8797, 0.8797]]]])\n",
      "tensor([2])\n",
      "Epoch: 3\t150.00% complete. 1.14 seconds elapsed in epoch.\n",
      "Epoch: 3 \tTraining Loss: 0.6920 \tValidation Loss: 0.9042\n",
      "\t\tTraining Accuracy: 25.00%\t Validation Accuracy: 25.00%\n",
      "tensor([[[[1.4783, 1.4783, 1.4783,  ..., 1.4783, 1.4783, 1.4783],\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.4783, 1.4783, 1.4783],\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.4783, 1.4783, 1.4783],\n",
      "          ...,\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.4269, 1.4954, 1.4783],\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.5125, 1.4783, 1.5125],\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.4954, 1.4783, 1.5125]],\n",
      "\n",
      "         [[1.5182, 1.5182, 1.5182,  ..., 1.5182, 1.5182, 1.5182],\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.5182, 1.5182, 1.5182],\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.5182, 1.5182, 1.5182],\n",
      "          ...,\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.4657, 1.5357, 1.4832],\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.5532, 1.5182, 1.5182],\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.5357, 1.5182, 1.5182]],\n",
      "\n",
      "         [[0.7925, 0.7925, 0.7925,  ..., 0.7925, 0.7925, 0.7925],\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.7925, 0.7925, 0.7925],\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.7925, 0.7925, 0.7925],\n",
      "          ...,\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.7228, 0.8448, 0.7402],\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.8099, 0.8274, 0.7751],\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.8099, 0.8274, 0.7751]]]])\n",
      "tensor([0])\n",
      "tensor([[[[-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          ...,\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          ...,\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062]]]])\n",
      "tensor([1])\n",
      "tensor([[[[2.1804, 1.1872, 0.6563,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2147, 1.5468, 1.2728,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.1975, 1.2899, 0.8618,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          ...,\n",
      "          [0.0912, 0.0912, 0.0912,  ..., 0.0912, 0.0912, 0.0912],\n",
      "          [0.0912, 0.0912, 0.0912,  ..., 0.0912, 0.0912, 0.0912],\n",
      "          [0.0912, 0.0912, 0.0912,  ..., 0.0912, 0.0912, 0.0912]],\n",
      "\n",
      "         [[2.3585, 1.3431, 0.8004,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.3936, 1.7108, 1.4307,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.3761, 1.4482, 1.0105,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          ...,\n",
      "          [1.0805, 1.0805, 1.0805,  ..., 1.0805, 1.0805, 1.0805],\n",
      "          [1.0805, 1.0805, 1.0805,  ..., 1.0805, 1.0805, 1.0805],\n",
      "          [1.0805, 1.0805, 1.0805,  ..., 1.0805, 1.0805, 1.0805]],\n",
      "\n",
      "         [[2.5703, 1.5594, 1.0191,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6051, 1.9254, 1.6465,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.5877, 1.6640, 1.2282,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          ...,\n",
      "          [0.8797, 0.8797, 0.8797,  ..., 0.8797, 0.8797, 0.8797],\n",
      "          [0.8797, 0.8797, 0.8797,  ..., 0.8797, 0.8797, 0.8797],\n",
      "          [0.8797, 0.8797, 0.8797,  ..., 0.8797, 0.8797, 0.8797]]]])\n",
      "tensor([2])\n",
      "Epoch: 4\t150.00% complete. 1.10 seconds elapsed in epoch.\n",
      "Epoch: 4 \tTraining Loss: 1.1534 \tValidation Loss: 0.9191\n",
      "\t\tTraining Accuracy: 0.00%\t Validation Accuracy: 25.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1.4783, 1.4783, 1.4783,  ..., 1.4783, 1.4783, 1.4783],\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.4783, 1.4783, 1.4783],\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.4783, 1.4783, 1.4783],\n",
      "          ...,\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.4269, 1.4954, 1.4783],\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.5125, 1.4783, 1.5125],\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.4954, 1.4783, 1.5125]],\n",
      "\n",
      "         [[1.5182, 1.5182, 1.5182,  ..., 1.5182, 1.5182, 1.5182],\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.5182, 1.5182, 1.5182],\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.5182, 1.5182, 1.5182],\n",
      "          ...,\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.4657, 1.5357, 1.4832],\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.5532, 1.5182, 1.5182],\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.5357, 1.5182, 1.5182]],\n",
      "\n",
      "         [[0.7925, 0.7925, 0.7925,  ..., 0.7925, 0.7925, 0.7925],\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.7925, 0.7925, 0.7925],\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.7925, 0.7925, 0.7925],\n",
      "          ...,\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.7228, 0.8448, 0.7402],\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.8099, 0.8274, 0.7751],\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.8099, 0.8274, 0.7751]]]])\n",
      "tensor([0])\n",
      "tensor([[[[-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          ...,\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          ...,\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062]]]])\n",
      "tensor([1])\n",
      "tensor([[[[2.1804, 1.1872, 0.6563,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2147, 1.5468, 1.2728,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.1975, 1.2899, 0.8618,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          ...,\n",
      "          [0.0912, 0.0912, 0.0912,  ..., 0.0912, 0.0912, 0.0912],\n",
      "          [0.0912, 0.0912, 0.0912,  ..., 0.0912, 0.0912, 0.0912],\n",
      "          [0.0912, 0.0912, 0.0912,  ..., 0.0912, 0.0912, 0.0912]],\n",
      "\n",
      "         [[2.3585, 1.3431, 0.8004,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.3936, 1.7108, 1.4307,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.3761, 1.4482, 1.0105,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          ...,\n",
      "          [1.0805, 1.0805, 1.0805,  ..., 1.0805, 1.0805, 1.0805],\n",
      "          [1.0805, 1.0805, 1.0805,  ..., 1.0805, 1.0805, 1.0805],\n",
      "          [1.0805, 1.0805, 1.0805,  ..., 1.0805, 1.0805, 1.0805]],\n",
      "\n",
      "         [[2.5703, 1.5594, 1.0191,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6051, 1.9254, 1.6465,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.5877, 1.6640, 1.2282,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          ...,\n",
      "          [0.8797, 0.8797, 0.8797,  ..., 0.8797, 0.8797, 0.8797],\n",
      "          [0.8797, 0.8797, 0.8797,  ..., 0.8797, 0.8797, 0.8797],\n",
      "          [0.8797, 0.8797, 0.8797,  ..., 0.8797, 0.8797, 0.8797]]]])\n",
      "tensor([2])\n",
      "Epoch: 5\t150.00% complete. 1.14 seconds elapsed in epoch.\n",
      "Epoch: 5 \tTraining Loss: 0.7779 \tValidation Loss: 0.9065\n",
      "\t\tTraining Accuracy: 50.00%\t Validation Accuracy: 0.00%\n",
      "\n",
      "Early Stopping! Total epochs: 5. Best epoch: 2 with loss: 0.85 and acc: 0.00%\n",
      "17.12 total seconds elapsed. 2.85 seconds per epoch.\n"
     ]
    }
   ],
   "source": [
    "model, history = train(\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    test_loader,\n",
    "    test_loader,\n",
    "    save_file_name=save_file_name,\n",
    "    max_epochs_stop=3,\n",
    "    n_epochs=100,\n",
    "    print_every=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
