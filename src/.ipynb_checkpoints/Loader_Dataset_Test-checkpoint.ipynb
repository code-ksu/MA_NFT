{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae599fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e6e84ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_save_path_X_train = 'D:\\\\Code\\\\datascience\\\\MA_NFT\\\\data\\\\pickle\\\\dummy_x.pkl'\n",
    "pickle_save_path_y_train = 'D:\\\\Code\\\\datascience\\\\MA_NFT\\\\data\\\\pickle\\\\dummy_y.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "541745d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_x = pd.DataFrame(data={\n",
    "    'param1': [0.005, 0.24, 0.99, 0.000998],\n",
    "    'param2': [0.005, 0.24, 0.99, 0.000998],\n",
    "    'param3': [0.005, 0.24, 0.99, 0.000998],\n",
    "    'id': ['1', '2', '3' , '4'],\n",
    "    'img_path': ['C:\\\\nft_data\\\\preview\\\\__hqB34BOi708uD1pUK1_noext.png', None, None, None],\n",
    "    'preview_path': [None, 'C:\\\\nft_data\\\\preview\\\\Z9_LE34BOa5kXuiNx1Au_noext.png', \n",
    "                     'C:\\\\nft_data\\\\preview\\\\z13JZn4B3CmUIj-Jo9QZ_noext.png', None]\n",
    "})\n",
    "# $:\n",
    "#df_y = pd.Series([2, 20, 423456, 423456]).astype('category')\n",
    "df_y = pd.Series([0, 1, 2, 2]).astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfddc85a",
   "metadata": {},
   "source": [
    "df_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a909293",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(pickle_save_path_X_train,'wb') as path_name:\n",
    "#    pickle.dump(df_x, path_name)\n",
    "#with open(pickle_save_path_y_train,'wb') as path_name:\n",
    "#    pickle.dump(df_y, path_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5253e1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0881d3",
   "metadata": {},
   "source": [
    "import torchvision.transforms as T\n",
    "trf = T.Compose([T.RandomResizedCrop(size=250, scale=(0.8, 1.0)),\n",
    "             T.CenterCrop(224),\n",
    "             T.RandomRotation(degrees=15),\n",
    "             T.ColorJitter(),\n",
    "             T.RandomHorizontalFlip(),\n",
    "             T.ToTensor(), \n",
    "             T.Normalize(mean = [0.485, 0.456, 0.406], \n",
    "                         std = [0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40a0c38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image transformations\n",
    "img_transforms = {\n",
    "    # Train uses data augmentation\n",
    "    'train':\n",
    "    T.Compose([\n",
    "        T.RandomResizedCrop(size=250, scale=(0.8, 1.0)),\n",
    "        T.RandomRotation(degrees=15),\n",
    "        T.ColorJitter(),\n",
    "        T.RandomHorizontalFlip(),\n",
    "        T.CenterCrop(size=224),  # Image net standards\n",
    "        T.ToTensor(),\n",
    "        T.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])  # Imagenet standards\n",
    "    ]),\n",
    "    # Validation does not use augmentation\n",
    "    'valid':\n",
    "    T.Compose([\n",
    "        T.Resize(size=250),\n",
    "        T.CenterCrop(size=224),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    \n",
    "        # Test does not use augmentation\n",
    "    'test':\n",
    "    T.Compose([\n",
    "        T.Resize(size=250),\n",
    "        T.CenterCrop(size=224),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ccfc8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_dataset import PickleMultiDataset\n",
    "#from collate import collate_none_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab45d20",
   "metadata": {},
   "source": [
    "with open(pickle_save_path,'wb') as path_name:\n",
    "    pickle.dump(img_df, path_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b498be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = PickleMultiDataset(pickle_save_path_X_train, pickle_save_path_y_train, img_transforms['train'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aae40f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG NOT FOUND in: ..\\..\\opensea_scapper\\opensea_nft_scrapper\\data\\preview\\1_noext.png\n",
      "tensor([0.2400, 0.2400, 0.2400], dtype=torch.float64)\n",
      "tensor([0.9900, 0.9900, 0.9900], dtype=torch.float64)\n",
      "IMG NOT FOUND in: ..\\..\\opensea_scapper\\opensea_nft_scrapper\\data\\preview\\4_noext.png\n"
     ]
    }
   ],
   "source": [
    "for ii, (img, data, target) in enumerate(ds_test):\n",
    "    #print(img, data, target)\n",
    "    print(data)\n",
    "    #print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "851fc3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(\n",
    "        ds_test, \n",
    "        batch_size=2,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        #collate_fn=collate_none_values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ae5811e",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 3\n",
    "BATCH_SIZE = 1024\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_FEATURES = 3\n",
    "NUM_CLASSES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b5894df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision # torch package for vision related things\n",
    "import torch.nn.functional as F  # Parameterless functions, like (some) activation functions\n",
    "import torchvision.datasets as datasets  # Standard datasets\n",
    "import torchvision.transforms as transforms  # Transformations we can perform on our dataset for augmentation\n",
    "from torch import optim  # For optimizers like SGD, Adam, etc.\n",
    "from torch import nn  # All neural network modules\n",
    "from torch.utils.data import DataLoader  # Gives easier dataset managment by creating mini batches etc.\n",
    "from tqdm import tqdm  # For nice progress bar!\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15215fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiInputResNet(nn.Module):\n",
    "    def __init__(self, num_feature, num_class):\n",
    "        super(MultiInputResNet, self).__init__()\n",
    "        # TAB MODEL\n",
    "        self.layer_1 = nn.Linear(num_feature, 512)\n",
    "        self.layer_2 = nn.Linear(512, 128)\n",
    "        self.layer_3 = nn.Linear(128, 64)\n",
    "        self.layer_out = nn.Linear(64, num_class) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(512)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(128)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(64)\n",
    "        #self.layer_1 = nn.Linear(num_feature, 2048)\n",
    "        #self.layer_2 = nn.Linear(2048, 512)\n",
    "        #self.layer_3 = nn.Linear(512, 32)\n",
    "        \n",
    "        #self.dropout = nn.Dropout(p=0.2)\n",
    "        #self.batchnorm1 = nn.BatchNorm1d(2048)\n",
    "        #self.batchnorm2 = nn.BatchNorm1d(512)\n",
    "        #self.batchnorm3 = nn.BatchNorm1d(32)\n",
    "        \n",
    "        #self.output = nn.Sequential(\n",
    "        #  nn.Linear(32, 250), \n",
    "        #  nn.ReLU(), \n",
    "        #  nn.Dropout(0.4),\n",
    "        #  nn.Linear(250, num_class),                   \n",
    "        #  nn.LogSoftmax(dim=1)\n",
    "        #)\n",
    "            \n",
    "    def forward_1(self, data) -> Tensor:\n",
    "        # TAB MODEL\n",
    "        print(data)\n",
    "        tab = self.layer_1(data)\n",
    "        tab = self.batchnorm1(tab)\n",
    "        tab = self.relu(tab)\n",
    "        \n",
    "        tab = self.layer_2(tab)\n",
    "        tab = self.batchnorm2(tab)\n",
    "        tab = self.relu(tab)\n",
    "        tab = self.dropout(tab)\n",
    "        \n",
    "        tab = self.layer_3(tab)\n",
    "        tab = self.batchnorm3(tab)\n",
    "        tab = self.relu(tab)\n",
    "        tab = self.dropout(tab)\n",
    "        \n",
    "        tab = self.layer_out(tab)\n",
    "        \n",
    "        x = self.output(tab)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layer_1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.layer_2(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.layer_3(x)\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a58d614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d7cdeb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiInputResNet(\n",
      "  (layer_1): Linear(in_features=3, out_features=512, bias=True)\n",
      "  (layer_2): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (layer_3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (layer_out): Linear(in_features=64, out_features=2, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (batchnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MultiInputResNet(num_feature=NUM_FEATURES, num_class=NUM_CLASSES)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "#print(model)\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(),  lr=LEARNING_RATE)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56d5e084",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_acc(y_pred, y_test):\n",
    "    y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
    "    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)    \n",
    "    \n",
    "    correct_pred = (y_pred_tags == y_test).float()\n",
    "    acc = correct_pred.sum() / len(correct_pred)\n",
    "    \n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0d0f374",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_stats = {\n",
    "    'train': [],\n",
    "    \"val\": []\n",
    "}\n",
    "loss_stats = {\n",
    "    'train': [],\n",
    "    \"val\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df9b1f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e4f6e3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                 | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2400, 0.2400, 0.2400], device='cuda:0', dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                 | 0/3 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected more than 1 value per channel when training, got input size torch.Size([1, 512])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13780/1233393347.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0my_train_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\deep\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13780/3296304524.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatchnorm1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\deep\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\deep\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning_mean\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning_var\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m         return F.batch_norm(\n\u001b[0m\u001b[0;32m    136\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[1;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\deep\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2142\u001b[0m         )\n\u001b[0;32m   2143\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2144\u001b[1;33m         \u001b[0m_verify_batch_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2146\u001b[0m     return torch.batch_norm(\n",
      "\u001b[1;32m~\\miniconda3\\envs\\deep\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36m_verify_batch_size\u001b[1;34m(size)\u001b[0m\n\u001b[0;32m   2109\u001b[0m         \u001b[0msize_prods\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2110\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_prods\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2111\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expected more than 1 value per channel when training, got input size {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected more than 1 value per channel when training, got input size torch.Size([1, 512])"
     ]
    }
   ],
   "source": [
    "print(\"Begin training.\")\n",
    "for e in tqdm(range(1, EPOCHS+1)):\n",
    "    \n",
    "    # TRAINING\n",
    "    train_epoch_loss = 0\n",
    "    train_epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    for img, X_train_batch, y_train_batch in train_loader:\n",
    "        X_train_batch, y_train_batch = X_train_batch.to(device), y_train_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        print(X_train_batch)\n",
    "        \n",
    "        y_train_pred = model(X_train_batch.float())\n",
    "        \n",
    "        train_loss = criterion(y_train_pred, y_train_batch)\n",
    "        train_acc = multi_acc(y_train_pred, y_train_batch)\n",
    "        \n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_epoch_loss += train_loss.item()\n",
    "        train_epoch_acc += train_acc.item()\n",
    "        \n",
    "        \n",
    "    # VALIDATION    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        val_epoch_loss = 0\n",
    "        val_epoch_acc = 0\n",
    "        \n",
    "        model.eval()\n",
    "        for X_val_batch, y_val_batch in val_loader:\n",
    "            X_val_batch, y_val_batch = X_val_batch.to(device), y_val_batch.to(device)\n",
    "            \n",
    "            y_val_pred = model(X_val_batch)\n",
    "                        \n",
    "            val_loss = criterion(y_val_pred, y_val_batch)\n",
    "            val_acc = multi_acc(y_val_pred, y_val_batch)\n",
    "            \n",
    "            val_epoch_loss += val_loss.item()\n",
    "            val_epoch_acc += val_acc.item()\n",
    "\n",
    "    loss_stats['train'].append(train_epoch_loss/len(train_loader))\n",
    "    loss_stats['val'].append(val_epoch_loss/len(val_loader))\n",
    "    accuracy_stats['train'].append(train_epoch_acc/len(train_loader))\n",
    "    accuracy_stats['val'].append(val_epoch_acc/len(val_loader))\n",
    "                              \n",
    "    \n",
    "print(f\"\"\"Epoch {e+0:03}:| Train Loss:\n",
    "      {train_epoch_loss/len(train_loader):.5f} | Val Loss:\n",
    "      {val_epoch_loss/len(val_loader):.5f} | Train Acc:\n",
    "      {train_epoch_acc/len(train_loader):.3f}| Val Acc:\n",
    "      {val_epoch_acc/len(val_loader):.3f}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9483008e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82b6e35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f792f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7348e6ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cac64e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374351ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc957c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc9568e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a73594",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974331de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d460941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELMENT 0\n",
      "tensor(10)\n",
      "ELMENT 1\n",
      "tensor(2)\n",
      "ELMENT 2\n",
      "tensor(300)\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for l in test_loader:\n",
    "    for (img, t) in l:\n",
    "        print(f'ELMENT {i}')\n",
    "        print(t)\n",
    "        i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c72416aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_29296/1150282151.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mii\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "for ii, (data, target) in enumerate(test_loader):\n",
    "    print(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9c6f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29459954",
   "metadata": {},
   "outputs": [],
   "source": [
    "[b for b in [1,2,3,None,5] if b is not None ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5905cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = PickleSeriesDataset(pickle_save_path_X_train, pickle_save_path_y_train, trf)\n",
    "list(DataLoader(ds, num_workers=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788a1535",
   "metadata": {},
   "source": [
    "# Test ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0347a050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cluster_name': 'es-docker-cluster',\n",
       " 'status': 'yellow',\n",
       " 'timed_out': False,\n",
       " 'number_of_nodes': 1,\n",
       " 'number_of_data_nodes': 1,\n",
       " 'active_primary_shards': 15,\n",
       " 'active_shards': 15,\n",
       " 'relocating_shards': 0,\n",
       " 'initializing_shards': 0,\n",
       " 'unassigned_shards': 2,\n",
       " 'delayed_unassigned_shards': 0,\n",
       " 'number_of_pending_tasks': 0,\n",
       " 'number_of_in_flight_fetch': 0,\n",
       " 'task_max_waiting_in_queue_millis': 0,\n",
       " 'active_shards_percent_as_number': 88.23529411764706}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch_dsl import Search\n",
    "import json\n",
    "import requests\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# create a client instance of the library\n",
    "elastic_client = Elasticsearch(timeout=60, max_retries=10, retry_on_timeout=True)\n",
    "elastic_client.cluster.health(wait_for_status='yellow', request_timeout=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59986d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from glob import glob\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "#from torchsummary import summary\n",
    "from torchvision import transforms, datasets, models\n",
    "import torch\n",
    "from torch import optim, cuda\n",
    "from torch.utils.data import DataLoader, sampler\n",
    "import torch.nn as nn\n",
    "import tqdm\n",
    "from timeit import default_timer as timer\n",
    "from torch import Tensor, nn\n",
    "from torch.nn.functional import interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a1b184e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file_name = 'C:\\\\NFT_data\\\\networks\\\\resnet50-transfer_test.pt'\n",
    "checkpoint_path = 'C:\\\\NFT_data\\\\networks\\\\resnet50-transfer_test.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb0ad18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on gpu: True\n",
      "1 gpus detected.\n",
      "True False\n"
     ]
    }
   ],
   "source": [
    "# Change to fit hardware\n",
    "batch_size = 1024\n",
    "\n",
    "# Whether to train on a gpu\n",
    "train_on_gpu = cuda.is_available()\n",
    "print(f'Train on gpu: {train_on_gpu}')\n",
    "\n",
    "# Number of gpus\n",
    "if train_on_gpu:\n",
    "    gpu_count = cuda.device_count()\n",
    "    print(f'{gpu_count} gpus detected.')\n",
    "    if gpu_count > 1:\n",
    "        multi_gpu = True\n",
    "    else:\n",
    "        multi_gpu = False\n",
    "print(train_on_gpu,multi_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59a18ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [2, 20, 423456]\n",
    "# restart for ResNet\n",
    "# Step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b20f2483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.0-2.0', '2.0-20.0', '20.0-423456.0']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_labels = []\n",
    "for i in range(0, len(bins)):\n",
    "    start = 0\n",
    "    if i > 0:\n",
    "        start = bins[i-1]\n",
    "    end = bins[i]\n",
    "    s = '{:.1f}'.format(start)\n",
    "    e = '{:.1f}'.format(end)\n",
    "    bin_labels.append(f'{s}-{e}')\n",
    "bin_labels\n",
    "# restart for ResNet\n",
    "# Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6f90a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0.0-2.0': 0, '2.0-20.0': 1, '20.0-423456.0': 2}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_class = {\n",
    "    idx: class_\n",
    "    for idx, class_ in enumerate(bin_labels)\n",
    "}\n",
    "class_to_idx = {bin_labels[i]: i for i in range(len(bin_labels))}\n",
    "\n",
    "class_to_idx\n",
    "# Restart for ResNet\n",
    "# Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b280c0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 different classes.\n"
     ]
    }
   ],
   "source": [
    "n_classes = len(bin_labels)\n",
    "print(f'There are {n_classes} different classes.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06b62d8",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa87fac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained = True)\n",
    "#Freeze our model's weights because we use pretrained one\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c9e1718",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = model.fc.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d742e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Sequential(\n",
    "                      nn.Linear(n_inputs, 250), \n",
    "                      nn.ReLU(), \n",
    "                      nn.Dropout(0.4),\n",
    "                      nn.Linear(250, n_classes),                   \n",
    "                      nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0058e864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2048, out_features=250, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Dropout(p=0.4, inplace=False)\n",
       "  (3): Linear(in_features=250, out_features=3, bias=True)\n",
       "  (4): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f4ff6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24,021,035 total parameters.\n",
      "513,003 training parameters.\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'{total_params:,} total parameters.')\n",
    "total_trainable_params = sum(\n",
    "    p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'{total_trainable_params:,} training parameters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53cc4ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_on_gpu:\n",
    "    model = model.to('cuda')\n",
    "\n",
    "if multi_gpu:\n",
    "    model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5d65d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=2048, out_features=250, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Dropout(p=0.4, inplace=False)\n",
      "  (3): Linear(in_features=250, out_features=3, bias=True)\n",
      "  (4): LogSoftmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "if multi_gpu:\n",
    "    print(model.module.fc)\n",
    "else:\n",
    "    print(model.fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bb03661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '0.0-2.0'), (1, '2.0-20.0'), (2, '20.0-423456.0')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.class_to_idx = class_to_idx\n",
    "model.idx_to_class = idx_to_class\n",
    "\n",
    "list(model.idx_to_class.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3bf63629",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3d0fbfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([250, 2048])\n",
      "torch.Size([250])\n",
      "torch.Size([3, 250])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "for p in optimizer.param_groups[0]['params']:\n",
    "    if p.requires_grad:\n",
    "        print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86817989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "trf = T.Compose([T.Resize(250),\n",
    "             T.CenterCrop(224),\n",
    "             T.ToTensor(), \n",
    "             T.Normalize(mean = [0.485, 0.456, 0.406], \n",
    "                         std = [0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1963c98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickledataset import PickleSeriesDataset\n",
    "from collate import collate_none_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc87e860",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(\n",
    "        PickleSeriesDataset(pickle_save_path_X_train, pickle_save_path_y_train, trf), \n",
    "        batch_size=2,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        #collate_fn=collate_none_values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "208434e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,\n",
    "          criterion,\n",
    "          optimizer,\n",
    "          train_loader,\n",
    "          valid_loader,\n",
    "          save_file_name,\n",
    "          max_epochs_stop=3,\n",
    "          n_epochs=20,\n",
    "          print_every=1):\n",
    "    \"\"\"Train a PyTorch Model\n",
    "\n",
    "    Params\n",
    "    --------\n",
    "        model (PyTorch model): cnn to train\n",
    "        criterion (PyTorch loss): objective to minimize\n",
    "        optimizer (PyTorch optimizier): optimizer to compute gradients of model parameters\n",
    "        train_loader (PyTorch dataloader): training dataloader to iterate through\n",
    "        valid_loader (PyTorch dataloader): validation dataloader used for early stopping\n",
    "        save_file_name (str ending in '.pt'): file path to save the model state dict\n",
    "        max_epochs_stop (int): maximum number of epochs with no improvement in validation loss for early stopping\n",
    "        n_epochs (int): maximum number of training epochs\n",
    "        print_every (int): frequency of epochs to print training stats\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "        model (PyTorch model): trained cnn with best weights\n",
    "        history (DataFrame): history of train and validation loss and accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    # Early stopping intialization\n",
    "    epochs_no_improve = 0\n",
    "    valid_loss_min = np.Inf\n",
    "\n",
    "    valid_max_acc = 0\n",
    "    history = []\n",
    "\n",
    "    # Number of epochs already trained (if using loaded in model weights)\n",
    "    try:\n",
    "        print(f'Model has been trained for: {model.epochs} epochs.\\n')\n",
    "    except:\n",
    "        model.epochs = 0\n",
    "        print(f'Starting Training from Scratch.\\n')\n",
    "\n",
    "    overall_start = timer()\n",
    "\n",
    "    # Main loop\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        # keep track of training and validation loss each epoch\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "\n",
    "        train_acc = 0\n",
    "        valid_acc = 0\n",
    "\n",
    "        # Set to training\n",
    "        model.train()\n",
    "        start = timer()\n",
    "\n",
    "        # Training loop\n",
    "        for ii, (data, target) in enumerate(train_loader):\n",
    "        #ii = 0\n",
    "        #for worker_data in train_loader:\n",
    "        #    for (data, target) in worker_data:\n",
    "                print(data)\n",
    "                print(target)\n",
    "\n",
    "                # Tensors to gpu\n",
    "                if train_on_gpu:\n",
    "                    data, target = data.cuda(), target.cuda()\n",
    "\n",
    "                # Clear gradients\n",
    "                optimizer.zero_grad()\n",
    "                # Predicted outputs are log probabilities\n",
    "                output = model(data)\n",
    "\n",
    "                # Loss and backpropagation of gradients\n",
    "                loss = criterion(output, target)\n",
    "                loss.backward()\n",
    "\n",
    "                # Update the parameters\n",
    "                optimizer.step()\n",
    "\n",
    "                # Track train loss by multiplying average loss by number of examples in batch\n",
    "                train_loss += loss.item() * data.size(0)\n",
    "\n",
    "                # Calculate accuracy by finding max log probability\n",
    "                _, pred = torch.max(output, dim=1)\n",
    "                correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "                # Need to convert correct tensor from int to float to average\n",
    "                accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n",
    "                # Multiply average accuracy times the number of examples in batch\n",
    "                train_acc += accuracy.item() * data.size(0)\n",
    "\n",
    "                # Track training progress\n",
    "                print(\n",
    "                    f'Epoch: {epoch}\\t{100 * (ii + 1) / len(train_loader):.2f}% complete. {timer() - start:.2f} seconds elapsed in epoch.',\n",
    "                    end='\\r')\n",
    "                \n",
    "                # increase\n",
    "                ii += 1\n",
    "\n",
    "        # After training loops ends, start validation\n",
    "        else:\n",
    "            model.epochs += 1\n",
    "\n",
    "            # Don't need to keep track of gradients\n",
    "            with torch.no_grad():\n",
    "                # Set to evaluation mode\n",
    "                model.eval()\n",
    "\n",
    "                # Validation loop\n",
    "                for data, target in valid_loader:\n",
    "                    # Tensors to gpu\n",
    "                    if train_on_gpu:\n",
    "                        data, target = data.cuda(), target.cuda()\n",
    "\n",
    "                    # Forward pass\n",
    "                    output = model(data)\n",
    "\n",
    "                    # Validation loss\n",
    "                    loss = criterion(output, target)\n",
    "                    # Multiply average loss times the number of examples in batch\n",
    "                    valid_loss += loss.item() * data.size(0)\n",
    "\n",
    "                    # Calculate validation accuracy\n",
    "                    _, pred = torch.max(output, dim=1)\n",
    "                    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "                    accuracy = torch.mean(\n",
    "                        correct_tensor.type(torch.FloatTensor))\n",
    "                    # Multiply average accuracy times the number of examples\n",
    "                    valid_acc += accuracy.item() * data.size(0)\n",
    "\n",
    "                # Calculate average losses\n",
    "                train_loss = train_loss / len(train_loader.dataset)\n",
    "                valid_loss = valid_loss / len(valid_loader.dataset)\n",
    "\n",
    "                # Calculate average accuracy\n",
    "                train_acc = train_acc / len(train_loader.dataset)\n",
    "                valid_acc = valid_acc / len(valid_loader.dataset)\n",
    "\n",
    "                history.append([train_loss, valid_loss, train_acc, valid_acc])\n",
    "\n",
    "                # Print training and validation results\n",
    "                if (epoch + 1) % print_every == 0:\n",
    "                    print(\n",
    "                        f'\\nEpoch: {epoch} \\tTraining Loss: {train_loss:.4f} \\tValidation Loss: {valid_loss:.4f}'\n",
    "                    )\n",
    "                    print(\n",
    "                        f'\\t\\tTraining Accuracy: {100 * train_acc:.2f}%\\t Validation Accuracy: {100 * valid_acc:.2f}%'\n",
    "                    )\n",
    "\n",
    "                # Save the model if validation loss decreases\n",
    "                if valid_loss < valid_loss_min:\n",
    "                    # Save model\n",
    "                    torch.save(model.state_dict(), save_file_name)\n",
    "                    # Track improvement\n",
    "                    epochs_no_improve = 0\n",
    "                    valid_loss_min = valid_loss\n",
    "                    valid_best_acc = valid_acc\n",
    "                    best_epoch = epoch\n",
    "\n",
    "                # Otherwise increment count of epochs with no improvement\n",
    "                else:\n",
    "                    epochs_no_improve += 1\n",
    "                    # Trigger early stopping\n",
    "                    if epochs_no_improve >= max_epochs_stop:\n",
    "                        print(\n",
    "                            f'\\nEarly Stopping! Total epochs: {epoch}. Best epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%'\n",
    "                        )\n",
    "                        total_time = timer() - overall_start\n",
    "                        print(\n",
    "                            f'{total_time:.2f} total seconds elapsed. {total_time / (epoch+1):.2f} seconds per epoch.'\n",
    "                        )\n",
    "\n",
    "                        # Load the best state dict\n",
    "                        model.load_state_dict(torch.load(save_file_name))\n",
    "                        # Attach the optimizer\n",
    "                        model.optimizer = optimizer\n",
    "\n",
    "                        # Format history\n",
    "                        history = pd.DataFrame(\n",
    "                            history,\n",
    "                            columns=[\n",
    "                                'train_loss', 'valid_loss', 'train_acc',\n",
    "                                'valid_acc'\n",
    "                            ])\n",
    "                        return model, history\n",
    "\n",
    "    # Attach the optimizer\n",
    "    model.optimizer = optimizer\n",
    "    # Record overall time and print out stats\n",
    "    total_time = timer() - overall_start\n",
    "    print(\n",
    "        f'\\nBest epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%'\n",
    "    )\n",
    "    print(\n",
    "        f'{total_time:.2f} total seconds elapsed. {total_time / (epoch):.2f} seconds per epoch.'\n",
    "    )\n",
    "    # Format history\n",
    "    history = pd.DataFrame(\n",
    "        history,\n",
    "        columns=['train_loss', 'valid_loss', 'train_acc', 'valid_acc'])\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4f38195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training from Scratch.\n",
      "\n",
      "tensor([[[[1.4783, 1.4783, 1.4783,  ..., 1.4783, 1.4783, 1.4783],\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.4783, 1.4783, 1.4783],\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.4783, 1.4783, 1.4783],\n",
      "          ...,\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.4269, 1.4954, 1.4783],\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.5125, 1.4783, 1.5125],\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.4954, 1.4783, 1.5125]],\n",
      "\n",
      "         [[1.5182, 1.5182, 1.5182,  ..., 1.5182, 1.5182, 1.5182],\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.5182, 1.5182, 1.5182],\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.5182, 1.5182, 1.5182],\n",
      "          ...,\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.4657, 1.5357, 1.4832],\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.5532, 1.5182, 1.5182],\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.5357, 1.5182, 1.5182]],\n",
      "\n",
      "         [[0.7925, 0.7925, 0.7925,  ..., 0.7925, 0.7925, 0.7925],\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.7925, 0.7925, 0.7925],\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.7925, 0.7925, 0.7925],\n",
      "          ...,\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.7228, 0.8448, 0.7402],\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.8099, 0.8274, 0.7751],\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.8099, 0.8274, 0.7751]]]])\n",
      "tensor([0])\n",
      "tensor([[[[-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          ...,\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          ...,\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062]]]])\n",
      "tensor([1])\n",
      "tensor([[[[2.1804, 1.1872, 0.6563,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2147, 1.5468, 1.2728,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.1975, 1.2899, 0.8618,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          ...,\n",
      "          [0.0912, 0.0912, 0.0912,  ..., 0.0912, 0.0912, 0.0912],\n",
      "          [0.0912, 0.0912, 0.0912,  ..., 0.0912, 0.0912, 0.0912],\n",
      "          [0.0912, 0.0912, 0.0912,  ..., 0.0912, 0.0912, 0.0912]],\n",
      "\n",
      "         [[2.3585, 1.3431, 0.8004,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.3936, 1.7108, 1.4307,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.3761, 1.4482, 1.0105,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          ...,\n",
      "          [1.0805, 1.0805, 1.0805,  ..., 1.0805, 1.0805, 1.0805],\n",
      "          [1.0805, 1.0805, 1.0805,  ..., 1.0805, 1.0805, 1.0805],\n",
      "          [1.0805, 1.0805, 1.0805,  ..., 1.0805, 1.0805, 1.0805]],\n",
      "\n",
      "         [[2.5703, 1.5594, 1.0191,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6051, 1.9254, 1.6465,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.5877, 1.6640, 1.2282,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          ...,\n",
      "          [0.8797, 0.8797, 0.8797,  ..., 0.8797, 0.8797, 0.8797],\n",
      "          [0.8797, 0.8797, 0.8797,  ..., 0.8797, 0.8797, 0.8797],\n",
      "          [0.8797, 0.8797, 0.8797,  ..., 0.8797, 0.8797, 0.8797]]]])\n",
      "tensor([2])\n",
      "Epoch: 0\t150.00% complete. 2.91 seconds elapsed in epoch.\n",
      "Epoch: 0 \tTraining Loss: 1.4756 \tValidation Loss: 1.1504\n",
      "\t\tTraining Accuracy: 0.00%\t Validation Accuracy: 25.00%\n",
      "tensor([[[[1.4783, 1.4783, 1.4783,  ..., 1.4783, 1.4783, 1.4783],\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.4783, 1.4783, 1.4783],\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.4783, 1.4783, 1.4783],\n",
      "          ...,\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.4269, 1.4954, 1.4783],\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.5125, 1.4783, 1.5125],\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.4954, 1.4783, 1.5125]],\n",
      "\n",
      "         [[1.5182, 1.5182, 1.5182,  ..., 1.5182, 1.5182, 1.5182],\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.5182, 1.5182, 1.5182],\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.5182, 1.5182, 1.5182],\n",
      "          ...,\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.4657, 1.5357, 1.4832],\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.5532, 1.5182, 1.5182],\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.5357, 1.5182, 1.5182]],\n",
      "\n",
      "         [[0.7925, 0.7925, 0.7925,  ..., 0.7925, 0.7925, 0.7925],\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.7925, 0.7925, 0.7925],\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.7925, 0.7925, 0.7925],\n",
      "          ...,\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.7228, 0.8448, 0.7402],\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.8099, 0.8274, 0.7751],\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.8099, 0.8274, 0.7751]]]])\n",
      "tensor([0])\n",
      "tensor([[[[-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          ...,\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          ...,\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062]]]])\n",
      "tensor([1])\n",
      "tensor([[[[2.1804, 1.1872, 0.6563,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2147, 1.5468, 1.2728,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.1975, 1.2899, 0.8618,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          ...,\n",
      "          [0.0912, 0.0912, 0.0912,  ..., 0.0912, 0.0912, 0.0912],\n",
      "          [0.0912, 0.0912, 0.0912,  ..., 0.0912, 0.0912, 0.0912],\n",
      "          [0.0912, 0.0912, 0.0912,  ..., 0.0912, 0.0912, 0.0912]],\n",
      "\n",
      "         [[2.3585, 1.3431, 0.8004,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.3936, 1.7108, 1.4307,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.3761, 1.4482, 1.0105,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          ...,\n",
      "          [1.0805, 1.0805, 1.0805,  ..., 1.0805, 1.0805, 1.0805],\n",
      "          [1.0805, 1.0805, 1.0805,  ..., 1.0805, 1.0805, 1.0805],\n",
      "          [1.0805, 1.0805, 1.0805,  ..., 1.0805, 1.0805, 1.0805]],\n",
      "\n",
      "         [[2.5703, 1.5594, 1.0191,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6051, 1.9254, 1.6465,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.5877, 1.6640, 1.2282,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          ...,\n",
      "          [0.8797, 0.8797, 0.8797,  ..., 0.8797, 0.8797, 0.8797],\n",
      "          [0.8797, 0.8797, 0.8797,  ..., 0.8797, 0.8797, 0.8797],\n",
      "          [0.8797, 0.8797, 0.8797,  ..., 0.8797, 0.8797, 0.8797]]]])\n",
      "tensor([2])\n",
      "Epoch: 1\t150.00% complete. 1.05 seconds elapsed in epoch.\n",
      "Epoch: 1 \tTraining Loss: 1.3455 \tValidation Loss: 0.9175\n",
      "\t\tTraining Accuracy: 25.00%\t Validation Accuracy: 25.00%\n",
      "tensor([[[[1.4783, 1.4783, 1.4783,  ..., 1.4783, 1.4783, 1.4783],\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.4783, 1.4783, 1.4783],\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.4783, 1.4783, 1.4783],\n",
      "          ...,\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.4269, 1.4954, 1.4783],\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.5125, 1.4783, 1.5125],\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.4954, 1.4783, 1.5125]],\n",
      "\n",
      "         [[1.5182, 1.5182, 1.5182,  ..., 1.5182, 1.5182, 1.5182],\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.5182, 1.5182, 1.5182],\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.5182, 1.5182, 1.5182],\n",
      "          ...,\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.4657, 1.5357, 1.4832],\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.5532, 1.5182, 1.5182],\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.5357, 1.5182, 1.5182]],\n",
      "\n",
      "         [[0.7925, 0.7925, 0.7925,  ..., 0.7925, 0.7925, 0.7925],\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.7925, 0.7925, 0.7925],\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.7925, 0.7925, 0.7925],\n",
      "          ...,\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.7228, 0.8448, 0.7402],\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.8099, 0.8274, 0.7751],\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.8099, 0.8274, 0.7751]]]])\n",
      "tensor([0])\n",
      "tensor([[[[-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          ...,\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          ...,\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062]]]])\n",
      "tensor([1])\n",
      "tensor([[[[2.1804, 1.1872, 0.6563,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2147, 1.5468, 1.2728,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.1975, 1.2899, 0.8618,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          ...,\n",
      "          [0.0912, 0.0912, 0.0912,  ..., 0.0912, 0.0912, 0.0912],\n",
      "          [0.0912, 0.0912, 0.0912,  ..., 0.0912, 0.0912, 0.0912],\n",
      "          [0.0912, 0.0912, 0.0912,  ..., 0.0912, 0.0912, 0.0912]],\n",
      "\n",
      "         [[2.3585, 1.3431, 0.8004,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.3936, 1.7108, 1.4307,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.3761, 1.4482, 1.0105,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          ...,\n",
      "          [1.0805, 1.0805, 1.0805,  ..., 1.0805, 1.0805, 1.0805],\n",
      "          [1.0805, 1.0805, 1.0805,  ..., 1.0805, 1.0805, 1.0805],\n",
      "          [1.0805, 1.0805, 1.0805,  ..., 1.0805, 1.0805, 1.0805]],\n",
      "\n",
      "         [[2.5703, 1.5594, 1.0191,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6051, 1.9254, 1.6465,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.5877, 1.6640, 1.2282,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          ...,\n",
      "          [0.8797, 0.8797, 0.8797,  ..., 0.8797, 0.8797, 0.8797],\n",
      "          [0.8797, 0.8797, 0.8797,  ..., 0.8797, 0.8797, 0.8797],\n",
      "          [0.8797, 0.8797, 0.8797,  ..., 0.8797, 0.8797, 0.8797]]]])\n",
      "tensor([2])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2\t150.00% complete. 1.15 seconds elapsed in epoch.\n",
      "Epoch: 2 \tTraining Loss: 1.1558 \tValidation Loss: 0.8488\n",
      "\t\tTraining Accuracy: 0.00%\t Validation Accuracy: 25.00%\n",
      "tensor([[[[1.4783, 1.4783, 1.4783,  ..., 1.4783, 1.4783, 1.4783],\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.4783, 1.4783, 1.4783],\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.4783, 1.4783, 1.4783],\n",
      "          ...,\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.4269, 1.4954, 1.4783],\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.5125, 1.4783, 1.5125],\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.4954, 1.4783, 1.5125]],\n",
      "\n",
      "         [[1.5182, 1.5182, 1.5182,  ..., 1.5182, 1.5182, 1.5182],\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.5182, 1.5182, 1.5182],\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.5182, 1.5182, 1.5182],\n",
      "          ...,\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.4657, 1.5357, 1.4832],\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.5532, 1.5182, 1.5182],\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.5357, 1.5182, 1.5182]],\n",
      "\n",
      "         [[0.7925, 0.7925, 0.7925,  ..., 0.7925, 0.7925, 0.7925],\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.7925, 0.7925, 0.7925],\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.7925, 0.7925, 0.7925],\n",
      "          ...,\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.7228, 0.8448, 0.7402],\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.8099, 0.8274, 0.7751],\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.8099, 0.8274, 0.7751]]]])\n",
      "tensor([0])\n",
      "tensor([[[[-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          ...,\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          ...,\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062]]]])\n",
      "tensor([1])\n",
      "tensor([[[[2.1804, 1.1872, 0.6563,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2147, 1.5468, 1.2728,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.1975, 1.2899, 0.8618,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          ...,\n",
      "          [0.0912, 0.0912, 0.0912,  ..., 0.0912, 0.0912, 0.0912],\n",
      "          [0.0912, 0.0912, 0.0912,  ..., 0.0912, 0.0912, 0.0912],\n",
      "          [0.0912, 0.0912, 0.0912,  ..., 0.0912, 0.0912, 0.0912]],\n",
      "\n",
      "         [[2.3585, 1.3431, 0.8004,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.3936, 1.7108, 1.4307,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.3761, 1.4482, 1.0105,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          ...,\n",
      "          [1.0805, 1.0805, 1.0805,  ..., 1.0805, 1.0805, 1.0805],\n",
      "          [1.0805, 1.0805, 1.0805,  ..., 1.0805, 1.0805, 1.0805],\n",
      "          [1.0805, 1.0805, 1.0805,  ..., 1.0805, 1.0805, 1.0805]],\n",
      "\n",
      "         [[2.5703, 1.5594, 1.0191,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6051, 1.9254, 1.6465,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.5877, 1.6640, 1.2282,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          ...,\n",
      "          [0.8797, 0.8797, 0.8797,  ..., 0.8797, 0.8797, 0.8797],\n",
      "          [0.8797, 0.8797, 0.8797,  ..., 0.8797, 0.8797, 0.8797],\n",
      "          [0.8797, 0.8797, 0.8797,  ..., 0.8797, 0.8797, 0.8797]]]])\n",
      "tensor([2])\n",
      "Epoch: 3\t150.00% complete. 1.14 seconds elapsed in epoch.\n",
      "Epoch: 3 \tTraining Loss: 0.6920 \tValidation Loss: 0.9042\n",
      "\t\tTraining Accuracy: 25.00%\t Validation Accuracy: 25.00%\n",
      "tensor([[[[1.4783, 1.4783, 1.4783,  ..., 1.4783, 1.4783, 1.4783],\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.4783, 1.4783, 1.4783],\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.4783, 1.4783, 1.4783],\n",
      "          ...,\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.4269, 1.4954, 1.4783],\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.5125, 1.4783, 1.5125],\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.4954, 1.4783, 1.5125]],\n",
      "\n",
      "         [[1.5182, 1.5182, 1.5182,  ..., 1.5182, 1.5182, 1.5182],\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.5182, 1.5182, 1.5182],\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.5182, 1.5182, 1.5182],\n",
      "          ...,\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.4657, 1.5357, 1.4832],\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.5532, 1.5182, 1.5182],\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.5357, 1.5182, 1.5182]],\n",
      "\n",
      "         [[0.7925, 0.7925, 0.7925,  ..., 0.7925, 0.7925, 0.7925],\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.7925, 0.7925, 0.7925],\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.7925, 0.7925, 0.7925],\n",
      "          ...,\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.7228, 0.8448, 0.7402],\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.8099, 0.8274, 0.7751],\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.8099, 0.8274, 0.7751]]]])\n",
      "tensor([0])\n",
      "tensor([[[[-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          ...,\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          ...,\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062]]]])\n",
      "tensor([1])\n",
      "tensor([[[[2.1804, 1.1872, 0.6563,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2147, 1.5468, 1.2728,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.1975, 1.2899, 0.8618,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          ...,\n",
      "          [0.0912, 0.0912, 0.0912,  ..., 0.0912, 0.0912, 0.0912],\n",
      "          [0.0912, 0.0912, 0.0912,  ..., 0.0912, 0.0912, 0.0912],\n",
      "          [0.0912, 0.0912, 0.0912,  ..., 0.0912, 0.0912, 0.0912]],\n",
      "\n",
      "         [[2.3585, 1.3431, 0.8004,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.3936, 1.7108, 1.4307,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.3761, 1.4482, 1.0105,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          ...,\n",
      "          [1.0805, 1.0805, 1.0805,  ..., 1.0805, 1.0805, 1.0805],\n",
      "          [1.0805, 1.0805, 1.0805,  ..., 1.0805, 1.0805, 1.0805],\n",
      "          [1.0805, 1.0805, 1.0805,  ..., 1.0805, 1.0805, 1.0805]],\n",
      "\n",
      "         [[2.5703, 1.5594, 1.0191,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6051, 1.9254, 1.6465,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.5877, 1.6640, 1.2282,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          ...,\n",
      "          [0.8797, 0.8797, 0.8797,  ..., 0.8797, 0.8797, 0.8797],\n",
      "          [0.8797, 0.8797, 0.8797,  ..., 0.8797, 0.8797, 0.8797],\n",
      "          [0.8797, 0.8797, 0.8797,  ..., 0.8797, 0.8797, 0.8797]]]])\n",
      "tensor([2])\n",
      "Epoch: 4\t150.00% complete. 1.10 seconds elapsed in epoch.\n",
      "Epoch: 4 \tTraining Loss: 1.1534 \tValidation Loss: 0.9191\n",
      "\t\tTraining Accuracy: 0.00%\t Validation Accuracy: 25.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1.4783, 1.4783, 1.4783,  ..., 1.4783, 1.4783, 1.4783],\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.4783, 1.4783, 1.4783],\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.4783, 1.4783, 1.4783],\n",
      "          ...,\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.4269, 1.4954, 1.4783],\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.5125, 1.4783, 1.5125],\n",
      "          [1.4783, 1.4783, 1.4783,  ..., 1.4954, 1.4783, 1.5125]],\n",
      "\n",
      "         [[1.5182, 1.5182, 1.5182,  ..., 1.5182, 1.5182, 1.5182],\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.5182, 1.5182, 1.5182],\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.5182, 1.5182, 1.5182],\n",
      "          ...,\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.4657, 1.5357, 1.4832],\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.5532, 1.5182, 1.5182],\n",
      "          [1.5182, 1.5182, 1.5182,  ..., 1.5357, 1.5182, 1.5182]],\n",
      "\n",
      "         [[0.7925, 0.7925, 0.7925,  ..., 0.7925, 0.7925, 0.7925],\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.7925, 0.7925, 0.7925],\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.7925, 0.7925, 0.7925],\n",
      "          ...,\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.7228, 0.8448, 0.7402],\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.8099, 0.8274, 0.7751],\n",
      "          [0.7925, 0.7925, 0.7925,  ..., 0.8099, 0.8274, 0.7751]]]])\n",
      "tensor([0])\n",
      "tensor([[[[-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          ...,\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103],\n",
      "          [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -1.2103, -1.2103]],\n",
      "\n",
      "         [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          ...,\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "         [[ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          ...,\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062],\n",
      "          [ 1.1062,  1.1062,  1.1062,  ...,  1.1062,  1.1062,  1.1062]]]])\n",
      "tensor([1])\n",
      "tensor([[[[2.1804, 1.1872, 0.6563,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2147, 1.5468, 1.2728,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.1975, 1.2899, 0.8618,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          ...,\n",
      "          [0.0912, 0.0912, 0.0912,  ..., 0.0912, 0.0912, 0.0912],\n",
      "          [0.0912, 0.0912, 0.0912,  ..., 0.0912, 0.0912, 0.0912],\n",
      "          [0.0912, 0.0912, 0.0912,  ..., 0.0912, 0.0912, 0.0912]],\n",
      "\n",
      "         [[2.3585, 1.3431, 0.8004,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.3936, 1.7108, 1.4307,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.3761, 1.4482, 1.0105,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          ...,\n",
      "          [1.0805, 1.0805, 1.0805,  ..., 1.0805, 1.0805, 1.0805],\n",
      "          [1.0805, 1.0805, 1.0805,  ..., 1.0805, 1.0805, 1.0805],\n",
      "          [1.0805, 1.0805, 1.0805,  ..., 1.0805, 1.0805, 1.0805]],\n",
      "\n",
      "         [[2.5703, 1.5594, 1.0191,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6051, 1.9254, 1.6465,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.5877, 1.6640, 1.2282,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          ...,\n",
      "          [0.8797, 0.8797, 0.8797,  ..., 0.8797, 0.8797, 0.8797],\n",
      "          [0.8797, 0.8797, 0.8797,  ..., 0.8797, 0.8797, 0.8797],\n",
      "          [0.8797, 0.8797, 0.8797,  ..., 0.8797, 0.8797, 0.8797]]]])\n",
      "tensor([2])\n",
      "Epoch: 5\t150.00% complete. 1.14 seconds elapsed in epoch.\n",
      "Epoch: 5 \tTraining Loss: 0.7779 \tValidation Loss: 0.9065\n",
      "\t\tTraining Accuracy: 50.00%\t Validation Accuracy: 0.00%\n",
      "\n",
      "Early Stopping! Total epochs: 5. Best epoch: 2 with loss: 0.85 and acc: 0.00%\n",
      "17.12 total seconds elapsed. 2.85 seconds per epoch.\n"
     ]
    }
   ],
   "source": [
    "model, history = train(\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    test_loader,\n",
    "    test_loader,\n",
    "    save_file_name=save_file_name,\n",
    "    max_epochs_stop=3,\n",
    "    n_epochs=100,\n",
    "    print_every=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
